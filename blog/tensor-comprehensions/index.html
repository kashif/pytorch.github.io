<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      Tensor Comprehensions in PyTorch | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="Tensor Comprehensions (TC) is a tool that lowers the barrier for writing high-performance code. It generates GPU code from a simple high-level language and autotunes the code for specific input sizes.

" />

  <meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
  <meta name="twitter:image" content="https://pytorch.org/assets/images/social-share.jpg" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Tensor Comprehensions in PyTorch" />
<meta property="og:description" content="Tensor Comprehensions (TC) is a tool that lowers the barrier for writing high-performance code. It generates GPU code from a simple high-level language and autotunes the code for specific input sizes.

" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Tensor Comprehensions in PyTorch" />
<meta name="twitter:description" content="Tensor Comprehensions (TC) is a tool that lowers the barrier for writing high-performance code. It generates GPU code from a simple high-level language and autotunes the code for specific input sizes.

" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>

    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">Get Started</a>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://events.linuxfoundation.org/pytorch-conference/">
            <span class="dropdown-title">PyTorch Conference - 2024</span>
            <p>September 18-19 in San Francisco</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item active">
      <a href="/blog">Blog</a>
    </li>

    <li class="main-menu-item">
      <a href="https://pytorch.org/tutorials">Tutorials</a>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/docs">
            <span class="dropdown-title docs-title">PyTorch</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/audio">
            <span class="dropdown-title docs-title">torchaudio</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/text">
            <span class="dropdown-title docs-title">torchtext</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/vision">
            <span class="dropdown-title docs-title">torchvision</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torcharrow">
            <span class="dropdown-title docs-title">torcharrow</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/data">
            <span class="dropdown-title docs-title">TorchData</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torchrec">
            <span class="dropdown-title docs-title">TorchRec</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/serve">
            <span class="dropdown-title docs-title">TorchServe</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/xla/release/1.6/index.html">
            <span class="dropdown-title docs-title">PyTorch on XLA Devices</span>
            <p></p>
          </a>
        </div>
      </div>
    </li>

    

    <li class="main-menu-item ">

      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Resources
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/features">
            <span class=dropdown-title>About</span>
            <p>Learn about PyTorchâ€™s features and capabilities</p>
          </a>
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class=dropdown-title>Community stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/hub">
            <span class=dropdown-title>Models (Beta)</span>
            <p>Discover, publish, and reuse pre-trained models</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch">GitHub</a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">March 05, 2018</p>
            <h1>
                <a class="blog-title">Tensor Comprehensions in PyTorch</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Priya Goyal (FAIR), Nicolas Vasilache (FAIR), Oleksandr Zinenko (Inria & DI ENS), Theodoros Theodoridis (ETH ZÃ¼rich), Zachary DeVito (FAIR), William S. Moses (MIT CSAIL), Sven Verdoolaege (FAIR), Andrew Adams (FAIR), Albert Cohen (Inria & DI ENS & FAIR)
                      
                    </p>
                    <p>Tensor Comprehensions (TC) is a tool that lowers the barrier for writing high-performance code. It generates GPU code from a simple high-level language and autotunes the code for specific input sizes.</p>

<p><strong>We highly recommend reading the <a href="https://research.fb.com/announcing-tensor-comprehensions/">Tensor Comprehensions blogpost</a> first.</strong></p>

<p>If you ran into any of the following scenarios, TC is a useful tool for you.</p>

<ul>
  <li>
    <p>Your PyTorch layer is large and slow, and you contemplated writing a dedicated C++ or CUDA code for it. But you donâ€™t know how to program in CUDA or write low-level code.</p>
  </li>
  <li>
    <p>You wrote a CUDA layer, but it took a week to write, debug, optimize for speed. You wished you could do this in an hour.</p>
  </li>
  <li>
    <p>You want to fuse multiple layers like Conv-ReLU-BatchNorm or Linear-ReLU-Linear-ReLU in your network for speed, but it was quite difficult to comprehend</p>
  </li>
  <li>
    <p>Your research involves weird Tensor shapes that CuDNN and MKL are not optimized for. For example, you do convolutions of 13 x 24 with an input image of 143 x 55. You tried running it with CuDNN and it was slower than you wished.</p>
  </li>
  <li>
    <p>Your code is slowed-down by transposing Tensors constantly to fit a particular memory layout. You wish it was easy to write custom code that operates efficiently on your input layout.</p>
  </li>
</ul>

<p>Tensor Comprehensions are seamless to use in PyTorch, interoperating with PyTorch Tensors and <code class="language-plaintext highlighter-rouge">nn</code> Variables.</p>

<p>Let us run through using TC with PyTorch.</p>

<h4 id="1-install-the-package">1. Install the package</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda <span class="nb">install</span> <span class="nt">-c</span> pytorch <span class="nt">-c</span> tensorcomp tensor_comprehensions
</code></pre></div></div>

<p>At this time we only provide Linux-64 binaries which have been tested on Ubuntu 16.04 and CentOS7.</p>

<p>TC depends on heavyweight C++ projects such as <a href="http://halide-lang.org/">Halide</a>, <a href="https://github.com/wsmoses/Tapir-LLVM">Tapir-LLVM</a> and ISL. Hence, we rely on Anaconda to distribute these dependencies reliably. For the same reason, TC is not available via PyPI.</p>

<h4 id="2-import-the-python-package">2. Import the python package</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensor_comprehensions</span> <span class="k">as</span> <span class="n">tc</span>
</code></pre></div></div>

<h4 id="3-define-the-tc-expression-and-create-a-python-function">3. Define the TC expression and create a python function</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lang</span> <span class="o">=</span> <span class="s">"""
def fcrelu(float(B,M) I, float(N,M) W1, float(N) B1) -&gt; (O1) {
    O1(b, n) +=! I(b, m) * W1(n, m)
    O1(b, n) = O1(b, n) + B1(n)
    O1(b, n) = fmax(O1(b, n), 0)
}
"""</span>
<span class="n">fcrelu</span> <span class="o">=</span> <span class="n">tc</span><span class="p">.</span><span class="n">define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"fcrelu"</span><span class="p">)</span>
</code></pre></div></div>

<p>This <code class="language-plaintext highlighter-rouge">fcrelu</code> function takes PyTorch Tensors as input and returns a PyTorch Tensor. It takes input <code class="language-plaintext highlighter-rouge">I</code>, weight <code class="language-plaintext highlighter-rouge">W1</code>, bias <code class="language-plaintext highlighter-rouge">B1</code> and returns output <code class="language-plaintext highlighter-rouge">O1</code>.</p>

<h4 id="4-lets-create-some-dummy-input-tensors">4. Letâ€™s create some dummy input tensors</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">100</span>
<span class="n">I</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">B1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">).</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">).</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="5-now-autotune-the-function-for-your-input-sizes">5. Now autotune the function for your input sizes</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fcrelu</span><span class="p">.</span><span class="n">autotune</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">B1</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="s">"fcrelu_100_128_100.tc"</span><span class="p">)</span>
</code></pre></div></div>

<p>The autotuner is your biggest friend. You generally do not want to use a <code class="language-plaintext highlighter-rouge">tc</code> function without autotuning it first.</p>

<p>When the autotuning is running, the current best performance is displayed. If you are satisfied with the current result or you are out of time, stop the tuning procedure by pressing <code class="language-plaintext highlighter-rouge">Ctrl+C</code>.</p>

<p><code class="language-plaintext highlighter-rouge">cache</code> saves the results of the autotuned kernel search and saves it to the file <code class="language-plaintext highlighter-rouge">fcrelu_100_128_100.tc</code>. The next time you call the same line of code, it loads the results of the autotuning without recomputing it.</p>

<p>The autotuner has a few hyperparameters (just like your ConvNet has learning rate, number of layers, etc.). We pick reasonable defaults, but you can read about using advanced options <a href="https://facebookresearch.github.io/TensorComprehensions/framework/pytorch_integration/writing_layers.html#specifying-mapping-options">here</a>.</p>

<h4 id="6-call-the-function-with-the-inputs-to-get-your-result">6. Call the function with the inputs, to get your result</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">out</span> <span class="o">=</span> <span class="n">fcrelu</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">B1</span><span class="p">)</span>
</code></pre></div></div>

<p>Now, letâ€™s look at how to write TC expressions.</p>

<h2 id="a-quick-primer-on-the-tc-language">A quick primer on the TC language</h2>

<p>The TC notation focuses on the mathematical nature of the layer, leaving performance considerations to itâ€™s backend code that uses Halide and polyhedral compilation techniques which accumulate decades of cutting edge Loop Nest Optimization (LNO) research.</p>

<p>TC is close to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html">np.einsum</a>. We shall quickly learn TC by example</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lang</span> <span class="o">=</span> <span class="s">"""
def matmul(float(M,N) A, float(N,K) B) -&gt; (output) {
  output(i, j) +=! A(i, kk) * B(kk, j)
}
"""</span>
</code></pre></div></div>

<p>In this example, we define a function <code class="language-plaintext highlighter-rouge">matmul</code> which takes two input <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code> of shapes <code class="language-plaintext highlighter-rouge">M x N</code> and <code class="language-plaintext highlighter-rouge">N x K</code> and returns a single <code class="language-plaintext highlighter-rouge">output</code>. The shape of <code class="language-plaintext highlighter-rouge">output</code> is automatically inferred by the TC language (discussed below).</p>

<p>Letâ€™s look at this line:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">+=</span><span class="err">!</span> <span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">kk</span><span class="p">)</span> <span class="o">*</span> <span class="n">B</span><span class="p">(</span><span class="n">kk</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div>

<p>It says:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">output(i, j)</code> means output is 2D.</li>
  <li>for each location <code class="language-plaintext highlighter-rouge">output(i, j)</code>, we add (<code class="language-plaintext highlighter-rouge">+=</code>) <code class="language-plaintext highlighter-rouge">A(i, kk) * B(kk, j)</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">i</code> is well-defined as all locations in <code class="language-plaintext highlighter-rouge">A</code> dim=0, i.e. <code class="language-plaintext highlighter-rouge">i in range(0, M)</code></li>
  <li><code class="language-plaintext highlighter-rouge">j</code> is well-defined as all locations in <code class="language-plaintext highlighter-rouge">B</code> dim=1, i.e. <code class="language-plaintext highlighter-rouge">j in range(0, K)</code></li>
  <li><code class="language-plaintext highlighter-rouge">kk</code> is inferred as all locations from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">N</code></li>
</ul>

<p>The shape of output is inferred from the maximum values <code class="language-plaintext highlighter-rouge">i</code> and <code class="language-plaintext highlighter-rouge">j</code> can take, which is <code class="language-plaintext highlighter-rouge">M</code> and <code class="language-plaintext highlighter-rouge">K</code>, so output is of size <code class="language-plaintext highlighter-rouge">M x K</code>.</p>

<p>The <code class="language-plaintext highlighter-rouge">!</code> symbol initializes output with <code class="language-plaintext highlighter-rouge">0.0</code>. It is equivalent to:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">output</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="o">+=</span> <span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">kk</span><span class="p">)</span> <span class="o">*</span> <span class="n">B</span><span class="p">(</span><span class="n">kk</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Scalar inputs and range constraints: implement AvgPool2d</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""

def avgpool(float(B, C, H, W) input) -&gt; (output) {{
  output(b, c, h, w) += input(b, c, h * {sH} + kh, w * {sW} + kw) where kh in 0:{kH}, kw in 0:{kW}
}}

"""</span>
<span class="n">avgpool</span> <span class="o">=</span> <span class="n">tc</span><span class="p">.</span><span class="n">define</span><span class="p">(</span><span class="n">LANG</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"avgpool"</span><span class="p">,</span> <span class="n">constants</span><span class="o">=</span><span class="p">{</span><span class="s">"sH"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"sW"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"kH"</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s">"kW"</span><span class="p">:</span><span class="mi">2</span><span class="p">})</span>
</code></pre></div></div>

<p>here the <code class="language-plaintext highlighter-rouge">where</code> keyword can take ranges of values to operate on. <code class="language-plaintext highlighter-rouge">0:{kH}</code> is equivalent <code class="language-plaintext highlighter-rouge">range(kH)</code> in Python.</p>

<p>Note: the syntax for passing in scalars is subject to change in the next release.</p>

<h2 id="torchnn-layers">torch.nn layers</h2>

<p>We added some sugar-coating around the basic PyTorch integration of TC to make it easy to integrate TC into larger <code class="language-plaintext highlighter-rouge">torch.nn</code> models by defining the forward and backward TC expressions and taking <code class="language-plaintext highlighter-rouge">Variable</code> inputs / outputs.</p>

<h2 id="some-essentials-that-you-will-miss-were-working-on-them">Some essentials that you will miss (weâ€™re working on them)</h2>

<h3 id="autotuning-for-variable-length-sequences">Autotuning for variable-length sequences</h3>

<p>The TC auto-tuner requires all input sizes to be specified before-hand. For example, if you have input <code class="language-plaintext highlighter-rouge">I1</code> which is an image batch, the autotuner wants to know the exact shape of <code class="language-plaintext highlighter-rouge">I1</code> to generate an optimized kernel. You cannot specify: <code class="language-plaintext highlighter-rouge">image with height between 200 and 300</code>. This is more essential in sequence data such as NLP, where each sentence can have a different length.</p>

<p>The reason why the autotuner is non-parametric is because itâ€™s harder and harder to auto-tune parametric constraints, this is active research. Hence, for the first release, we made a conscious decision to give you the tool in a form where we know it works well.</p>

<p>As a work-around, if you know that you have a few specific shapes of interest, you can run the autotuner with these multiple shapes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">relu</span> <span class="o">=</span> <span class="n">tc</span><span class="p">.</span><span class="n">define</span><span class="p">(</span><span class="n">LANG</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)</span>
<span class="n">batch</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span>
<span class="n">tc</span><span class="p">.</span><span class="n">autotune</span><span class="p">((</span><span class="n">batch</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span> <span class="c1"># image of size 32 x 32
</span><span class="n">tc</span><span class="p">.</span><span class="n">autotune</span><span class="p">((</span><span class="n">batch</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span> <span class="c1"># image of size 48 x 48
</span><span class="n">tc</span><span class="p">.</span><span class="n">autotune</span><span class="p">((</span><span class="n">batch</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span> <span class="c1"># image of size 64 x 64
</span></code></pre></div></div>

<p>Now the autotuner is tuned for these three specific image sizes <code class="language-plaintext highlighter-rouge">32x32</code>, <code class="language-plaintext highlighter-rouge">48x48</code> and <code class="language-plaintext highlighter-rouge">64x64</code>.</p>

<h3 id="lack-of-loops">Lack of loops</h3>

<p>If you want to write an RNN, itâ€™s easy to see it as a <code class="language-plaintext highlighter-rouge">for</code> loop over time. However, the TC language does not have loops yet. If you really want to write RNNs, you can write unrolled loops.</p>

<h3 id="strided-tensors">Strided-Tensors</h3>

<p>The TC backend does not support non-contiguous Tensors yet. If the inputs you give are not contiguous, they are made contiguous before passing to the TC backend.</p>

<h3 id="reshaping-tensors-within-a-tc-expression">Reshaping Tensors within a TC expression</h3>

<p>You cannot write this operation in TC: <code class="language-plaintext highlighter-rouge">torch.matmul(...).view(...).mean(...)</code>. Whenever there is need for a <code class="language-plaintext highlighter-rouge">view</code> to change the shape of an input, you have to get the output, <code class="language-plaintext highlighter-rouge">view</code> it at the PyTorch level.</p>

<h2 id="getting-started">Getting Started</h2>

<ul>
  <li><a href="https://facebookresearch.github.io/TensorComprehensions/framework/pytorch_integration/writing_layers.html">Walk through Tutorial</a> to quickly get started with understanding and using Tensor Comprehensions PyTorch package.</li>
  <li>Over 20 examples of various ML layers with TC, including <code class="language-plaintext highlighter-rouge">avgpool</code>, <code class="language-plaintext highlighter-rouge">maxpool</code>, <code class="language-plaintext highlighter-rouge">matmul</code>, matmul - give output buffers and <code class="language-plaintext highlighter-rouge">batch-matmul</code>, <code class="language-plaintext highlighter-rouge">convolution</code>, <code class="language-plaintext highlighter-rouge">strided-convolution</code>, <code class="language-plaintext highlighter-rouge">batchnorm</code>, <code class="language-plaintext highlighter-rouge">copy</code>, <code class="language-plaintext highlighter-rouge">cosine similarity</code>, <code class="language-plaintext highlighter-rouge">Linear</code>, <code class="language-plaintext highlighter-rouge">Linear + ReLU</code>, <code class="language-plaintext highlighter-rouge">group-convolutions</code>, strided <code class="language-plaintext highlighter-rouge">group-convolutions</code>, <code class="language-plaintext highlighter-rouge">indexing</code>, <code class="language-plaintext highlighter-rouge">Embedding</code> (lookup table), small-mobilenet, <code class="language-plaintext highlighter-rouge">softmax</code>, <code class="language-plaintext highlighter-rouge">tensordot</code>, <code class="language-plaintext highlighter-rouge">transpose</code></li>
  <li><a href="https://facebookresearch.github.io/TensorComprehensions/framework/pytorch_integration/getting_started.html">Detailed docs</a> on Tensor Comprehensions and integration with PyTorch.</li>
</ul>

<h2 id="communication">Communication</h2>

<ul>
  <li>Slack: For discussion around framework integration, build support, collaboration, etc. join our slack channel.</li>
  <li>Email: tensorcomp@fb.com</li>
  <li><a href="https://github.com/facebookresearch/TensorComprehensions">GitHub</a>: bug reports, feature requests, install issues, RFCs, thoughts, etc.</li>
</ul>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>We would like to thank Soumith Chintala, <a href="https://github.com/ezyang">Edward Yang</a> and <a href="https://github.com/colesbury">Sam Gross</a> for their immense guidance and help in making the integration API nice and smooth. We would also like to thank rest of the PyTorch team and our pre-release users for their helpful feedback that guided us in making the integration better.</p>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.org" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.org">PyTorch</a></li>
          <li><a href="/get-started">Get Started</a></li>
          <li><a href="/features">Features</a></li>
          <li><a href="/ecosystem">Ecosystem</a></li>
          <li><a href="/blog">Blog</a></li>
          <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          <li><a href="https://github.com/pytorch/pytorch/security/policy" target="_blank">Security</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="/resources">Resources</a></li>
          <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
          <li><a href="/docs">Docs</a></li>
          <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
          <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">GitHub Issues</a></li>
          <li><a href="/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>Stay up to date</p></li>
          <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
          <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
          <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
          <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          <li><a href="https://social.lfx.dev/@pytorch" rel="me" target="_blank">Mastodon</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>PyTorch Podcasts</p></li>
          <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
          <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
          <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
          <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
        </ul>
      </div>
    </div>

    <div class="privacy-policy">
      <ul>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
        <li class="privacy-policy-links">|</li>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
      </ul>
      <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/legal/policies/">www.linuxfoundation.org/legal/policies/</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="">
          <a href="/get-started">Get Started</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://events.linuxfoundation.org/pytorch-conference/">PyTorch Conference - 2024</a>
          </li>
          <li>
            <a href="/ecosystem">Tools</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Edge</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
        </ul>

        <li class="active">
          <a href="/blog">Blog</a>
        </li>

        <li>
          <a href="https://pytorch.org/tutorials">Tutorials</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a href="/docs">Docs</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/docs">PyTorch</a>
          </li>

          <li class="">
            <a href="/audio">torchaudio</a>
          </li>

          <li class="">
            <a href="/text">torchtext</a>
          </li>

          <li class="">
            <a href="/vision">torchvision</a>
          </li>

          <li class="">
            <a href="/torcharrow">torcharrow</a>
          </li>

          <li class="">
            <a href="/data">TorchData</a>
          </li> 

          <li class="">
            <a href="/torchrec">TorchRec</a>
          </li>

          <li class="">
            <a href="/serve">TorchServe</a>
          </li>

          <li class="">
            <a href="/xla/release/1.6/index.html">PyTorch on XLA Devices</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          Resources
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/features">About</a>
          </li>

          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          
          <li>
            <a href="/#community-module">Community</a>
          </li>
          
          <li class="">
            <a href="/community-stories">Community stories</a>
          </li>

          <li class="">
            <a href="/resources">Developer Resources</a>
          </li>

          <li>
            <a href="/events">Events</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.org">Forum</a>
          </li>

          <li class="">
            <a href="/hub">Models (Beta)</a>
          </li>

        </ul>

        <li id="github-mobile-menu-link">
          <a href="https://github.com/pytorch/pytorch">GitHub</a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
